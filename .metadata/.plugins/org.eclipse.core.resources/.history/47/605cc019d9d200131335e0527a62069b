package upload;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.io.Text;

import java.io.FileReader;
import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;


/*
 *		Class fileUploader
 * 
 *		@desc Reads all the files in <<InputFolder>> and uploads them to HDS in <<OutputFolder>>
 *		@author Vicente Ruben Del Pino Ruiz <<ruben.delpino@gmail.com>>
 *
 */



public class fileUploader {
	
	
	//Input folder with files to upload
	//Output folder where upload the files (in HDFS)
	String OutputFolder;
	String InputFolder;
	
	
	//Cluster configuration 
	Configuration conf;
	FileSystem fs;
	
	public fileUploader(){
		
		try{
			//Open configuration for cluster
			conf= new Configuration();
			fs = FileSystem.get(conf);
		}
		catch (Exception IOException){
			System.out.println("Error reading configuration from cluster and setting Filesystem: "+IOException.getMessage());
		}
		
	}
	
	public fileUploader(String Folder){
		
		
		
		
		
		    
		    // Check if the file already exists
		    Path path = new Path("/path/to/file.ext");
		    if (fs.exists(path)) {
		        System.out.println("File " + dest + " already exists");
		        return;
		    }

		    // Create a new file and write data to it.
		    FSDataOutputStream out = fs.create(path);
		    InputStream in = new BufferedInputStream(new FileInputStream(
		        new File(source)));

		    byte[] b = new byte[1024];
		    int numBytes = 0;
		    while ((numBytes = in.read(b)) > 0) {
		        out.write(b, 0, numBytes);
		    }

		    // Close all the file descripters
		    in.close();
		    out.close();
		    fs.close();
		
	}
	
	
	
	
	
	
	
	

}
